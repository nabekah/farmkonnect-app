import { EventEmitter } from 'events';\n\nexport type RateLimitStrategy = 'fixed_window' | 'sliding_window' | 'token_bucket' | 'leaky_bucket';\nexport type ThrottleStrategy = 'adaptive' | 'priority_based' | 'fair_share';\n\nexport interface RateLimitConfig {\n  strategy: RateLimitStrategy;\n  windowSize: number; // milliseconds\n  maxRequests: number;\n  perUser?: boolean;\n  perIP?: boolean;\n  perEndpoint?: boolean;\n}\n\nexport interface ThrottleConfig {\n  strategy: ThrottleStrategy;\n  enabled: boolean;\n  targetLatency: number; // milliseconds\n  maxConcurrent: number;\n  queueSize: number;\n}\n\nexport interface RateLimitBucket {\n  userId?: string;\n  ip?: string;\n  endpoint?: string;\n  requests: number;\n  resetTime: number;\n  tokens?: number;\n}\n\nexport interface ThrottleQueue {\n  id: string;\n  priority: number;\n  timestamp: number;\n  callback: () => Promise<any>;\n}\n\nexport interface RateLimitStatistics {\n  totalRequests: number;\n  blockedRequests: number;\n  allowedRequests: number;\n  blockRate: number;\n  averageWaitTime: number;\n  peakConcurrency: number;\n}\n\nclass RateLimitingSystem extends EventEmitter {\n  private buckets: Map<string, RateLimitBucket> = new Map();\n  private config: RateLimitConfig;\n  private throttleConfig: ThrottleConfig;\n  private throttleQueue: ThrottleQueue[] = [];\n  private activeRequests: number = 0;\n  private maxConcurrent: number = 100;\n  private statistics: RateLimitStatistics = {\n    totalRequests: 0,\n    blockedRequests: 0,\n    allowedRequests: 0,\n    blockRate: 0,\n    averageWaitTime: 0,\n    peakConcurrency: 0,\n  };\n  private waitTimes: number[] = [];\n  private concurrencyHistory: number[] = [];\n\n  constructor(\n    config: RateLimitConfig = {\n      strategy: 'token_bucket',\n      windowSize: 60000,\n      maxRequests: 1000,\n      perUser: true,\n      perIP: false,\n      perEndpoint: false,\n    },\n    throttleConfig: ThrottleConfig = {\n      strategy: 'adaptive',\n      enabled: true,\n      targetLatency: 100,\n      maxConcurrent: 100,\n      queueSize: 1000,\n    }\n  ) {\n    super();\n    this.config = config;\n    this.throttleConfig = throttleConfig;\n    this.maxConcurrent = throttleConfig.maxConcurrent;\n    this.startCleanupInterval();\n  }\n\n  /**\n   * Check if request is allowed\n   */\n  checkRateLimit(\n    identifier: string,\n    endpoint?: string,\n    weight: number = 1\n  ): { allowed: boolean; retryAfter?: number; remaining?: number } {\n    this.statistics.totalRequests++;\n\n    const key = this.generateKey(identifier, endpoint);\n    let bucket = this.buckets.get(key);\n\n    if (!bucket) {\n      bucket = this.createBucket(key);\n    }\n\n    // Check if bucket has expired\n    if (Date.now() > bucket.resetTime) {\n      bucket = this.resetBucket(key);\n    }\n\n    const allowed = this.checkBucketLimit(bucket, weight);\n\n    if (allowed) {\n      bucket.requests += weight;\n      this.statistics.allowedRequests++;\n      this.emit('request:allowed', { identifier, endpoint, weight });\n\n      return {\n        allowed: true,\n        remaining: this.config.maxRequests - bucket.requests,\n      };\n    } else {\n      this.statistics.blockedRequests++;\n      const retryAfter = Math.ceil((bucket.resetTime - Date.now()) / 1000);\n      this.emit('request:blocked', { identifier, endpoint, retryAfter });\n\n      return {\n        allowed: false,\n        retryAfter,\n      };\n    }\n  }\n\n  /**\n   * Generate bucket key\n   */\n  private generateKey(identifier: string, endpoint?: string): string {\n    const parts = [identifier];\n\n    if (this.config.perEndpoint && endpoint) {\n      parts.push(endpoint);\n    }\n\n    return parts.join(':');\n  }\n\n  /**\n   * Create new bucket\n   */\n  private createBucket(key: string): RateLimitBucket {\n    const bucket: RateLimitBucket = {\n      requests: 0,\n      resetTime: Date.now() + this.config.windowSize,\n      tokens: this.config.maxRequests,\n    };\n\n    this.buckets.set(key, bucket);\n    return bucket;\n  }\n\n  /**\n   * Reset bucket\n   */\n  private resetBucket(key: string): RateLimitBucket {\n    const bucket = this.buckets.get(key)!;\n    bucket.requests = 0;\n    bucket.resetTime = Date.now() + this.config.windowSize;\n    bucket.tokens = this.config.maxRequests;\n    return bucket;\n  }\n\n  /**\n   * Check bucket limit based on strategy\n   */\n  private checkBucketLimit(bucket: RateLimitBucket, weight: number): boolean {\n    switch (this.config.strategy) {\n      case 'fixed_window':\n        return bucket.requests + weight <= this.config.maxRequests;\n\n      case 'sliding_window':\n        return this.checkSlidingWindow(bucket, weight);\n\n      case 'token_bucket':\n        return this.checkTokenBucket(bucket, weight);\n\n      case 'leaky_bucket':\n        return this.checkLeakyBucket(bucket, weight);\n\n      default:\n        return bucket.requests + weight <= this.config.maxRequests;\n    }\n  }\n\n  /**\n   * Sliding window check\n   */\n  private checkSlidingWindow(bucket: RateLimitBucket, weight: number): boolean {\n    const now = Date.now();\n    const windowStart = now - this.config.windowSize;\n\n    // Simplified sliding window\n    const elapsed = now - (bucket.resetTime - this.config.windowSize);\n    const allowance = (elapsed / this.config.windowSize) * this.config.maxRequests;\n\n    return bucket.requests + weight <= allowance + this.config.maxRequests;\n  }\n\n  /**\n   * Token bucket check\n   */\n  private checkTokenBucket(bucket: RateLimitBucket, weight: number): boolean {\n    if (!bucket.tokens) bucket.tokens = this.config.maxRequests;\n\n    const now = Date.now();\n    const timePassed = now - (bucket.resetTime - this.config.windowSize);\n    const tokensGenerated = (timePassed / this.config.windowSize) * this.config.maxRequests;\n\n    bucket.tokens = Math.min(this.config.maxRequests, bucket.tokens + tokensGenerated);\n\n    if (bucket.tokens >= weight) {\n      bucket.tokens -= weight;\n      return true;\n    }\n\n    return false;\n  }\n\n  /**\n   * Leaky bucket check\n   */\n  private checkLeakyBucket(bucket: RateLimitBucket, weight: number): boolean {\n    const now = Date.now();\n    const leakRate = this.config.maxRequests / this.config.windowSize; // requests per ms\n    const timePassed = now - (bucket.resetTime - this.config.windowSize);\n    const leaked = timePassed * leakRate;\n\n    const currentLevel = Math.max(0, bucket.requests - leaked);\n\n    if (currentLevel + weight <= this.config.maxRequests) {\n      bucket.requests = currentLevel + weight;\n      return true;\n    }\n\n    return false;\n  }\n\n  /**\n   * Queue request for throttling\n   */\n  async throttleRequest<T>(\n    callback: () => Promise<T>,\n    priority: number = 0,\n    identifier?: string\n  ): Promise<T> {\n    const startTime = Date.now();\n\n    // If under capacity, execute immediately\n    if (this.activeRequests < this.maxConcurrent) {\n      this.activeRequests++;\n      this.updateConcurrencyStats();\n\n      try {\n        const result = await callback();\n        return result;\n      } finally {\n        this.activeRequests--;\n        const waitTime = Date.now() - startTime;\n        this.recordWaitTime(waitTime);\n      }\n    }\n\n    // Queue the request\n    return new Promise((resolve, reject) => {\n      const queueItem: ThrottleQueue = {\n        id: `queue-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,\n        priority,\n        timestamp: Date.now(),\n        callback: async () => {\n          try {\n            const result = await callback();\n            resolve(result);\n          } catch (error) {\n            reject(error);\n          }\n        },\n      };\n\n      if (this.throttleQueue.length >= this.throttleConfig.queueSize) {\n        reject(new Error('Queue is full'));\n        this.emit('queue:full', { identifier });\n        return;\n      }\n\n      this.throttleQueue.push(queueItem);\n      this.sortQueue();\n      this.processQueue();\n    });\n  }\n\n  /**\n   * Sort queue based on strategy\n   */\n  private sortQueue(): void {\n    switch (this.throttleConfig.strategy) {\n      case 'priority_based':\n        this.throttleQueue.sort((a, b) => b.priority - a.priority);\n        break;\n\n      case 'fair_share':\n        // FIFO with priority boost for older items\n        this.throttleQueue.sort((a, b) => {\n          const ageBoostA = (Date.now() - a.timestamp) / 1000;\n          const ageBoostB = (Date.now() - b.timestamp) / 1000;\n          return b.priority + ageBoostB - (a.priority + ageBoostA);\n        });\n        break;\n\n      case 'adaptive':\n        // Adaptive based on current latency\n        const avgLatency = this.statistics.averageWaitTime;\n        if (avgLatency > this.throttleConfig.targetLatency) {\n          // Prioritize shorter operations\n          this.throttleQueue.sort((a, b) => b.priority - a.priority);\n        } else {\n          // FIFO\n          this.throttleQueue.sort((a, b) => a.timestamp - b.timestamp);\n        }\n        break;\n    }\n  }\n\n  /**\n   * Process queue\n   */\n  private async processQueue(): Promise<void> {\n    while (this.throttleQueue.length > 0 && this.activeRequests < this.maxConcurrent) {\n      const item = this.throttleQueue.shift();\n      if (!item) break;\n\n      this.activeRequests++;\n      this.updateConcurrencyStats();\n\n      const startTime = Date.now();\n\n      try {\n        await item.callback();\n      } catch (error) {\n        this.emit('request:error', { error, queueId: item.id });\n      } finally {\n        this.activeRequests--;\n        const waitTime = Date.now() - startTime;\n        this.recordWaitTime(waitTime);\n      }\n    }\n  }\n\n  /**\n   * Record wait time\n   */\n  private recordWaitTime(duration: number): void {\n    this.waitTimes.push(duration);\n\n    if (this.waitTimes.length > 10000) {\n      this.waitTimes.shift();\n    }\n\n    if (this.waitTimes.length > 0) {\n      this.statistics.averageWaitTime =\n        this.waitTimes.reduce((a, b) => a + b, 0) / this.waitTimes.length;\n    }\n  }\n\n  /**\n   * Update concurrency stats\n   */\n  private updateConcurrencyStats(): void {\n    this.concurrencyHistory.push(this.activeRequests);\n\n    if (this.concurrencyHistory.length > 1000) {\n      this.concurrencyHistory.shift();\n    }\n\n    this.statistics.peakConcurrency = Math.max(\n      this.statistics.peakConcurrency,\n      this.activeRequests\n    );\n  }\n\n  /**\n   * Get statistics\n   */\n  getStatistics(): RateLimitStatistics {\n    const stats = { ...this.statistics };\n    stats.blockRate =\n      stats.totalRequests > 0 ? (stats.blockedRequests / stats.totalRequests) * 100 : 0;\n    return stats;\n  }\n\n  /**\n   * Get queue status\n   */\n  getQueueStatus(): {\n    queueLength: number;\n    activeRequests: number;\n    maxConcurrent: number;\n    utilizationPercent: number;\n  } {\n    return {\n      queueLength: this.throttleQueue.length,\n      activeRequests: this.activeRequests,\n      maxConcurrent: this.maxConcurrent,\n      utilizationPercent: (this.activeRequests / this.maxConcurrent) * 100,\n    };\n  }\n\n  /**\n   * Reset statistics\n   */\n  resetStatistics(): void {\n    this.statistics = {\n      totalRequests: 0,\n      blockedRequests: 0,\n      allowedRequests: 0,\n      blockRate: 0,\n      averageWaitTime: 0,\n      peakConcurrency: 0,\n    };\n    this.waitTimes = [];\n    this.concurrencyHistory = [];\n  }\n\n  /**\n   * Update rate limit config\n   */\n  updateConfig(config: Partial<RateLimitConfig>): void {\n    this.config = { ...this.config, ...config };\n    this.emit('config:updated', this.config);\n  }\n\n  /**\n   * Update throttle config\n   */\n  updateThrottleConfig(config: Partial<ThrottleConfig>): void {\n    this.throttleConfig = { ...this.throttleConfig, ...config };\n    this.maxConcurrent = config.maxConcurrent || this.maxConcurrent;\n    this.emit('throttle:config:updated', this.throttleConfig);\n  }\n\n  /**\n   * Clear all buckets\n   */\n  clearBuckets(): void {\n    this.buckets.clear();\n    this.emit('buckets:cleared');\n  }\n\n  /**\n   * Start cleanup interval\n   */\n  private startCleanupInterval(): void {\n    setInterval(() => {\n      const now = Date.now();\n      let cleaned = 0;\n\n      for (const [key, bucket] of this.buckets.entries()) {\n        if (now > bucket.resetTime + this.config.windowSize * 2) {\n          this.buckets.delete(key);\n          cleaned++;\n        }\n      }\n\n      if (cleaned > 0) {\n        this.emit('cleanup:completed', { bucketsRemoved: cleaned });\n      }\n    }, 60000); // Run every minute\n  }\n\n  /**\n   * Get bucket info\n   */\n  getBucketInfo(identifier: string, endpoint?: string): RateLimitBucket | undefined {\n    const key = this.generateKey(identifier, endpoint);\n    return this.buckets.get(key);\n  }\n}\n\nexport default RateLimitingSystem;\n
